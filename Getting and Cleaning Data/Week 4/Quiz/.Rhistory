row.names(dt)
row.names(dt)[pos]
seq <- "O"
append("A")
append("A",seq)
seq
append(seq,"A")
seq
visited <- seq[seq[which(seq!="O")]]
visited
seq != "O"
seq == "O"
seq
seq <- append(seq,"A")
seq == "O"
seq != "O"
visited <- seq[seq != "O"]
visited
names(dt)
names(dt) != seq
index <- names(dt) != seq
dt["A"][index]
index
dt["A"]
dt["A"][,index]
dt["A"][index,]
index <- names(dt) != seq
row_temp <- DT[current][index,]
row_temp <- dt[current][index,]
row_temp <- dt["A"][index,]
row_temp
nearest <- min(row_temp)
dt
nearest
pos <- which(row_temp == nearest)
pos
row_temp
index <- names(dt) != seq
row_temp <- DT[current]
temp <- row_temp[index,]
row_temp <- dt[current]
temp <- row_temp[index,]
row_temp <- dt["A"]
temp <- row_temp[index,]
nearest <- min(temp)
nearest
pos <- which(row_temp == nearest)
pos
if (length(pos)> 1){
pos <- sample(pos,1)
}
current <- row.names(DT)[pos]
current <- row.names(dt)[pos]
current
seq <- append(seq,current)
seq
carry <- 2
if (carrying<cap){
index <- names(dt) != seq
row_temp <- DT[current]
temp <- row_temp[index,]
nearest <- min(temp)
pos <- which(row_temp == nearest)
if (length(pos)> 1){
pos <- sample(pos,1)
}
current <- row.names(DT)[pos]
seq <- append(seq,current)
carry <- carry +1
}else{
current <- "O"
carrying <- 0
seq <- append(seq,current)
}
carrying <- 2
if (carrying<cap){
index <- names(dt) != seq
row_temp <- DT[current]
temp <- row_temp[index,]
nearest <- min(temp)
pos <- which(row_temp == nearest)
if (length(pos)> 1){
pos <- sample(pos,1)
}
current <- row.names(DT)[pos]
seq <- append(seq,current)
carry <- carry +1
}else{
current <- "O"
carrying <- 0
seq <- append(seq,current)
}
if (carrying<3){
index <- names(dt) != seq
row_temp <- dt[current]
temp <- row_temp[index,]
nearest <- min(temp)
pos <- which(row_temp == nearest)
if (length(pos)> 1){
pos <- sample(pos,1)
}
current <- row.names(dt)[pos]
seq <- append(seq,current)
carry <- carry +1
}else{
current <- "O"
carrying <- 0
seq <- append(seq,current)
}
seq
dt
carrying
c(1,7:9)
cap <- 3
seq(LETTERS,3)
seq(LETTERS)
letters
install.packages("wikipediatrend")
install.packages(c("XML", "tidyr"))
library(wikipediatrend)
data <- wp_trend(page="Essilor", from = "2013-01-01", to = "2015-12-31")
View(data)
library(ggplot2)
qplot(date,count,data = data)
summary(data)
data$count[data$count == 0] <- NA
qplot(date,count,data = data)
ds <- data$date
y <- log(data$count)
df <- data.frame()
df <- data.frame(ds,y)
view(df)
df
View(df)
qplot(ds , y, data = df)
library(prophet)
library(Rcpp)
library(prophet)
m <- prophet(df)
future <- make_future_dataframe(m, periods = 365)
tail(future)
forecast <- predict(m,future)
tail(forecast)
tail(forecast[c('ds','yhat','yhat_lower','yhat_upper')])
exp(5.027693)
plot(m, forecast)
prophet_plot_components(m, forecast)
prophet_plot_components(m, forecast)
library(prophet)
library(Rccp)
library(Rcpp,prophet,ggplot2)
prophet_plot_components(m, forecast)
str(HoltWinters())
str(HoltWinters
)
HoltWinters(ds)
as.ts(ds)
ht <- as.ts(ds)
HoltWinters(ht)
head(ht)
ht <- as.ts(ds$log)
head(ds)
ht <- as.ts(df)
head(ht)
calc <- HoltWinters(ht)
data <- structure(c(12, 20.5, 21, 15.5, 15.3, 23.5, 24.5, 21.3, 23.5,
28, 24, 15.5, 17.3, 25.3, 25, 36.5, 36.5, 29.6, 30.5, 28, 26,
21.5, 19.7, 19, 16, 20.7, 26.5, 30.6, 32.3, 29.5, 28.3, 31.3,
32.2, 26.4, 23.4, 16.4, 15, 16, 18, 27, 21, 49, 21, 22, 28, 36,
40, 3, 21, 29, 62, 65, 46, 44, 33, 62, 22, 12, 24, 3, 5, 14,
36, 40, 49, 7, 52, 65, 17, 5, 17, 1),
.Dim = c(36L, 2L), .Dimnames = list(NULL, c("Advertising", "Sales")),
.Tsp = c(2006, 2008.91666666667, 12), class = c("mts", "ts", "matrix")
)
head(data); nrow(data)
plot(data)
ht <- HoltWinters(data)
head(ht)
plot(ht)
plot(fitted(m))
plot(fitted(ht))
train = tdat[1:31]
test = tdat[32:36]
arma_fit <- auto.arima(train)
arma_forecast <- forecast(arma_fit, h = 5)
arma_fit_accuracy <- accuracy(arma_forecast, test)
arma_fit; arma_forecast; arma_fit_accuracy
plot(arma_forecast, ylim=c(0,60))
lines(tdat[1:36])
train = tdat[1:31]
test = tdat[32:36]
arma_fit <- auto.arima(train)
arma_forecast <- forecast(arma_fit, h = 5)
arma_fit_accuracy <- accuracy(arma_forecast, test)
arma_fit; arma_forecast; arma_fit_accuracy
plot(arma_forecast, ylim=c(0,60))
lines(tdat[1:36])
library(forecast)
install.packages("forecast")
moving_average = forecast(ma(tdat[1:31], order=2), h=5)
moving_average_accuracy = accuracy(moving_average, tdat[32:36])
moving_average; moving_average_accuracy
plot(moving_average, ylim=c(0,60))
lines(tdat[1:36])
library(forecast)
moving_average = forecast(ma(tdat[1:31], order=2), h=5)
moving_average_accuracy = accuracy(moving_average, tdat[32:36])
moving_average; moving_average_accuracy
plot(moving_average, ylim=c(0,60))
lines(tdat[1:36])
class(data)
class(data$"mtcars")
class(ds)
class(ht)
clearPushBack()
restartDescription()
library(forecast,ggplot2,HoltWinters())
library(forecast,ggplot2,HoltWinters
)
library(forecast)
library(ggplot2)
library(tseries)
str(runs.test)
library(wikipediatrend)
data <- wp_trend(page="Essilor", from = "2013-01-01", to = "2015-12-31")
str(runs.test)
runs.test(data)
facData <- as.factor(data)
head(dat)
head(data)
facData <- as.factor(data$count)
runs.test(facData)
class(data)
facData <- as.factor(data$date,data$count)
facData <- as.factor(data$count)
head(facData)
install.packages("plier", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages("plyr", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages(c("rlang", "tibble"))
AreRedes <- rnorm(46065,58.2,3)
summary(AreRedes)
AreRedes <- rnorm(46065,58.2,9)
summary(AreRedes)
Redes <- rnorm(c(46065,16835),c(58.2,56.4),9)
head(Redes)
Redes <- sapply(n = c(46065,16835),rnorm,mean = c(58.2,56.4),sd = 9)
Redes <- sapply(n = c(46065,16835),FUN = rnorm,mean = c(58.2,56.4),sd = 9)
Redes <- sapply( x =  c(46065,16835),FUN = rnorm,mean = c(58.2,56.4),sd = 9)
Redes <- sapply( X =  c(46065,16835),FUN = rnorm,mean = c(58.2,56.4),sd = 9)
head(Redes)
head(Redes,10)
summary(Redes)
sapply(Redes,summary)
install.packages("tibble")
install.packages(c("Rcpp", "rlang", "shinydashboard", "tibble"), lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages("Hmisc", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages("plyr", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages("plyr", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
require(xlsx)
library("rJava");
java_home
library("rJava"); .jinit(); .jcall("java/lang/System", "S", "getProperty", "java.runtime.version")
install.packages("reshape2", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
require(reshape2)
library("rJava", lib.loc="~/Library/R/3.4/library")
detach("package:rJava", unload=TRUE)
head(mtcars)
install.packages("dplyr", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages("gdata")
install.packages("gdata", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library(swirl)
swirl
swirl()
read.c
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time
)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
select(cran,id)
select(cran,ip_id)
class(cran)
swirl()
filter(cran,country == "US", r_version =="3.1.1")
?Comparison
filter(cran,country == "IN", r_version <= "3.0.2")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500)
filter(cran, country == "US" | country == "IN")
ilter(cran, size > 100500, r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
install.packages("dplyr")
library(swirl)
swirl()
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(select(cran,r_version)))
View(cran)
filter(cran,!is.na(select(cran,r_version)))
filter(cran,!is.na(r_version))
select(cran2,size:ip_id)
cran2 <- select(cran,size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <- select(cran,ip_id, package,size)
cran3
make_tbl(cars)
dim(cars)
as.tbl(cars)
swirl()
mutate(cran3,size_mb = size/2^20)
mutate(cran3,size_mb = size/2^20,size_gb= size_mb / 2^10)
mutate(cran3,corretct_size = size+1000)
mutate(cran3,correct_size = size + 1000)
summarise(cran,avg_bytes = mean(size))
summarize(cran,avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package)
summarize(by_package,mean(size))
n?
?n
?n_distinct
submit()
pack_sum
quantile(pack_sum$count,probs = 0.99)
filter(pack_sum,count > 679)
top_counts <- filter(pack_sum,count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,desc(count)
)
View(top_counts_sorted)
quantile(pack_sum$unique,probs = 0.99)
top_unique <- filter(pack_sum,uniaue > 465)
View(pack_sum)
top_unique <- filter(pack_sum , uniaue > 465)
top_unique <- filter(pack_sum, uniaue>465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique)
)
View()
View(top_unique_sorted)
submit
submit()
submit()
?chain
??chain
submit
submit()
View(result3)
submit()
submit()
submit()
submit()
install.packages("dplyr")
install.packages("dplyr", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
setwd("~/GitHub/DataScienceSpecialization/Getting and Cleaning Data/Week 4/Quiz")
rm(list = ls())
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv","housingID.csv")
library(readr)
housingID <- read_csv("~/GitHub/DataScienceSpecialization/Getting and Cleaning Data/Week 4/Quiz/housingID.csv")
View(housingID)
list <- strsplit(names(housingID))
Snames <- strsplit(names(housingID),split = "wgtp")
Snames
Snames[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf","DicHousing.pdf")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","gdp.csv")
GDP <- read.csv2("gdp.csv")
head(GDP)
GDP <- read.csv2("gdp.csv",sep = ",")
View(GDP)
library(dplyr)
class(GDP$X.3)
GDP$X.3[196]
GDP$X.3[,196]
GDP$X.3[[196]]
GDP$X.3 == ".."
GDP <- filter(GDP, GDP$X.3 =! ".." )
GDP <- filter(GDP, (GDP$X.3 =! "..") )
GDP <- filter(GDP, (GDP$X.3 =! ".."))
f <- GDP$X.3 == ".."
GDP <- filter(GDP, f
)
library(stringr)
sub(",","",GDP$X.3)
GDP$X.3
library(readr)
gdp <- read_csv("~/GitHub/DataScienceSpecialization/Getting and Cleaning Data/Week 4/Quiz/gdp.csv",
col_types = cols(X5 = col_character()),
skip = 4)
View(gdp)
sub(",","",gdp$X5)
gsub(",","",gdp$X5)
n <- as.numeric(gsub(",","",gdp$X5))
mean(n,na.rm = TRUE)
library(readr)
gdp2 <- read_csv("~/GitHub/DataScienceSpecialization/Getting and Cleaning Data/Week 4/Quiz/gdp.csv",
skip = 4)
View(gdp2)
mean(gdp2, na.rm = TRUE)
mean(gdp2)
mean(gdp2$X5, na.rm = TRUE)
mean(as.numeric(gdp2$X5), na.rm = TRUE)
noc <- gsub(",","",gdp2$X5)
noc
noc <- noc[!is.na(noc)]
noc
noc <- noc[!(noc == "..")]
noc
mean(as.numeric(noc))
noc <- sub(",","",gdp2$X5)
noc <- sub(",",".",gdp2$X5)
noc
noc <- sub(",","",gdp2$X5)
noc <- sub(",",".",noc)
noc
noc <- noc[!(is.na(noc)|noc == "..") ]
noc
mean(as.numeric(noc))
noc
noc[1:190]
mean(noc[1:190])
mean(as.numeric(noc[1:190]))
noc <- sub(".",",noc")
noc <- sub(".","",noc)
noc
noc <- sub(".","",noc)
noc
noc <- sub("\.","",noc)
noc <- sub(".","",noc)
noc
noc <- gsub(",","",gdp2$X5)
noc
as.numeric(noc)
mean(as.numeric(noc),na.rm = T)
mean(as.numeric(noc),na.rm = TRUE)
length(noc)
length(noc[1:190])
mean(as.numeric(noc[1:190]),na.rm = TRUE)
View(gdp)
grepl("^United",gdp2$X4)
grep("^United",gdp2$X4)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","EduGDP.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv","EduGDP.csv")
library(readr)
EduGDP <- read_csv("~/GitHub/DataScienceSpecialization/Getting and Cleaning Data/Week 4/Quiz/EduGDP.csv")
View(EduGDP)
test <- merge(EduGDP,gdp2,by.x = "CountryCode")
test <- merge(EduGDP,gdp2,by.x = "CountryCode", by.y = "X1")
substr(test$`Special Notes`,19,27)
substr(test$`Special Notes`,18,27)
grep("^June", substr(test$`Special Notes`,18,27))
grepl("^June", substr(test$`Special Notes`,18,27))
sum(grepl("^June", substr(test$`Special Notes`,18,27)))
install.packages("quantmod", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
amzn
class(amzn)
dates <- amzn[,1]
dates
class(dates)
dates[[,1]]
dates[1,1]
dates[,1]
is.xts(dates)
as.Date.POSIXct(dates)
head(sampleTimes)
class(sampleTimes)
library(lubridate)
days <- day(sampleTimes)
head(days)
days <- day(sampleTimes, label = TRUE)
days <- Wday(sampleTimes, label = TRUE)
days <- wday(sampleTimes, label = TRUE)
head(days)
table
table(days)
dt <- data.frame(wday(sampleTimes, label = TRUE),year(sampleTimes))
head(dt)
dt %>% group_by(wday.sampleTimes..label...TRUE.) %>% summarize(count = n(), year = mean(year.sampleTimes.))
dt %>% group_by(wday.sampleTimes..label...TRUE.) %>% group_by(year.sampleTimes.)
dt %>% group_by(wday.sampleTimes..label...TRUE.) %>% group_by(year.sampleTimes.) %>% summarise(count = n())
dt %>% filter(year.sampleTimes. == 2012) %>% group_by(wday.sampleTimes..label...TRUE.) %>% summarise(count = n())
res <- dt %>% filter(year.sampleTimes. == 2012) %>% group_by(wday.sampleTimes..label...TRUE.) %>% summarise(count = n())
sum(res$count)
